{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"theta_layer_18/Reshape_2:0\", shape=(?, 1, ?, 1), dtype=float32)\n",
      "input shape [(None, 10, 1), (None, 1)]\n",
      "Tensor(\"theta_layer_18_1/Reshape_2:0\", shape=(?, 1, ?, 1), dtype=float32)\n",
      "input shape [(None, 10, 1), (None, 1)]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_i (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_j (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_vgg (Model)                (None, 10, 1)        139611210   input_i[0][0]                    \n",
      "                                                                 input_j[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "theta_layer_18 (ThetaLayer)     (None, 1)            10000       base_vgg[1][0]                   \n",
      "                                                                 input[0][0]                      \n",
      "                                                                 base_vgg[2][0]                   \n",
      "                                                                 input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 1)            0           theta_layer_18[0][0]             \n",
      "                                                                 theta_layer_18[1][0]             \n",
      "==================================================================================================\n",
      "Total params: 139,621,210\n",
      "Trainable params: 139,621,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "w = 224\n",
    "h = 224\n",
    "input_shape = (w, h, 3)\n",
    "dropout = 0.2\n",
    "latent_d = 10 # latent dimension\n",
    "\n",
    "user_num = 1000 # for test, this should be obtained from the dataset\n",
    "\n",
    "\n",
    "def euclidean_distance(vects): \n",
    "    # L2 distance\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_i = layers.Input(shape=input_shape, name=\"input_i\") # image of item i\n",
    "input_j = layers.Input(shape=input_shape, name=\"input_j\") # image of item j\n",
    "input_idx = layers.Input(shape=[1], name=\"input_user\", dtype='int32') # idx of user u\n",
    "\n",
    "\n",
    "# customer layer, learn the latent matrix of theta_u\n",
    "class ThetaLayer(Layer):\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='theta_u_matrix', \n",
    "                                      shape=(user_num, latent_d),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(ThetaLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        item, u = x # u: user idx; item: visual feature of item \n",
    "        print (K.dot(K.gather(self.kernel, u), item))\n",
    "        return K.dot(K.gather(self.kernel, u), item)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print('input shape', input_shape)\n",
    "        return (input_shape[0][0], 1)\n",
    "\n",
    "\n",
    "# load the VGG pretrained on imagenet\n",
    "def create_base_vgg(dropout):\n",
    "    vgg = keras.applications.vgg19.VGG19(\n",
    "        include_top=False, # whether to include the fc layers\n",
    "        weights='imagenet', \n",
    "        input_tensor=None, \n",
    "        input_shape=input_shape, \n",
    "        pooling=None, \n",
    "        classes=1000)\n",
    "    x = vgg.output\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(latent_d, activation='softmax', name='predictions')(x)\n",
    "    x = layers.Reshape(target_shape=(latent_d, 1))(x)\n",
    "    \n",
    "    return Model(inputs = vgg.input, outputs = x, name=\"base_vgg\")\n",
    "\n",
    "\n",
    "\n",
    "# because we re-use the same instance `base_vgg`, theta_layer,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "base_vgg = create_base_vgg(dropout)\n",
    "theta = ThetaLayer()\n",
    "\n",
    "x1 = base_vgg(input_i)\n",
    "x1 = theta([x1, input_idx])\n",
    "\n",
    "x2 = base_vgg(input_j)\n",
    "x2 = theta([x2, input_idx])\n",
    "\n",
    "# distance = layers.Lambda(euclidean_distance,\n",
    "#                   output_shape=eucl_dist_output_shape)([x1, x2])\n",
    "            \n",
    "distance = layers.Subtract()([x1, x2])\n",
    "\n",
    "\n",
    "model = Model([input_i, input_j, input_idx], distance)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "def load_image(file_path):\n",
    "    img = image.load_img(f_path, target_size=(w, h))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------------------metrics---------------------------\n",
    "# auc_roc as the metrics\n",
    "# for details about how to implement auc in keras, see https://github.com/keras-team/keras/issues/3230\n",
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "\n",
    "# ----------------------loss function---------------------------\n",
    "# not sure which loss function is better\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def entropy_loss(y_true, y_pred):\n",
    "    ''' from Comparative Deep Learning of Hybrid Representations for Image Recommendations\n",
    "    https://arxiv.org/pdf/1604.01252.pdf\n",
    "    use crose entropy as the loss\n",
    "    '''\n",
    "    margin = 1\n",
    "    y_pred = K.sigmoid(y_pred)\n",
    "    sqaure_pred = -K.log(y_pred)\n",
    "    margin_square = -K.log(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "# ----------------------optimizer---------------------------\n",
    "# optimizer: rms or adam?\n",
    "rms = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: freeze all convolutional layers, only train fc layers (which were randomly initialized)\n",
    "for layer in base_vgg.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in base_vgg.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# set trainable layers before model compile\n",
    "model.compile(optimizer=rms, loss=contrastive_loss, metrics = [auc])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
