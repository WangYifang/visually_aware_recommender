{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputa (InputLayer)             (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputb (InputLayer)             (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_vgg (Model)                (None, 4096)         139570240   inputa[0][0]                     \n",
      "                                                                 inputb[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           base_vgg[1][0]                   \n",
      "                                                                 base_vgg[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 139,570,240\n",
      "Trainable params: 139,570,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "w = 224\n",
    "h = 224\n",
    "input_shape = (w, h, 3)\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "def euclidean_distance(vects): \n",
    "    # l2 distance\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_a = layers.Input(shape=input_shape, name=\"inputa\")\n",
    "input_b = layers.Input(shape=input_shape, name=\"inputb\")\n",
    "\n",
    "\n",
    "# load the VGG pretrained on imagenet\n",
    "def create_base_vgg(dropout):\n",
    "    vgg = keras.applications.vgg19.VGG19(\n",
    "        include_top=False, # whether to include the fc layers\n",
    "        weights='imagenet', \n",
    "        input_tensor=None, \n",
    "        input_shape=input_shape, \n",
    "        pooling=None, \n",
    "        classes=1000)\n",
    "    x = vgg.output\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "#     x = layers.Dropout(dropout)(x)\n",
    "#     x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    return Model(inputs = vgg.input, outputs = x, name=\"base_vgg\")\n",
    "\n",
    "# because we re-use the same instance `base_vgg`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "base_vgg = create_base_vgg(dropout)\n",
    "x1 = base_vgg(input_a)\n",
    "x2 = base_vgg(input_b)\n",
    "\n",
    "distance = layers.Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([x1, x2])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "def load_image(file_path):\n",
    "    img = image.load_img(f_path, target_size=(w, h))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------------------metrics---------------------------\n",
    "# auc_roc as the metrics\n",
    "# for details, see https://github.com/keras-team/keras/issues/3230\n",
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "\n",
    "# ----------------------loss function---------------------------\n",
    "# not sure which loss function is better\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def entropy_loss(y_true, y_pred):\n",
    "    ''' from Comparative Deep Learning of Hybrid Representations for Image Recommendations\n",
    "    https://arxiv.org/pdf/1604.01252.pdf\n",
    "    use crose entropy as the loss\n",
    "    '''\n",
    "    margin = 1\n",
    "    y_pred = K.sigmoid(y_pred)\n",
    "    sqaure_pred = -K.log(y_pred)\n",
    "    margin_square = -K.log(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "# ----------------------optimizer---------------------------\n",
    "# optimizer: rms or adam?\n",
    "rms = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# freeze all convolutional layers, train fc layers\n",
    "for layer in base_vgg.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in base_vgg.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# set trainable layers before model compile\n",
    "model.compile(optimizer=rms, loss=contrastive_loss, metrics = [auc])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
